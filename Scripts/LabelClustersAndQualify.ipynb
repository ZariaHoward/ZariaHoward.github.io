{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groom_list\n",
      "error2 groom_list9875.jpeg 9875\n",
      "error3 groom_list9875.jpeg 9875 9875.jpeg <type 'numpy.string_'> 9 done\n",
      "error2 groom_list9872.jpeg 9872\n",
      "error3 groom_list9872.jpeg 9872 9872.jpeg <type 'numpy.string_'> 9 done\n",
      "lab_list\n",
      "error2 lab_list9857.jpeg 9857\n",
      "error3 lab_list9857.jpeg 9857 9857.jpeg <type 'numpy.string_'> 9 done\n",
      "cinema_list\n",
      "piano_list\n",
      "barb_list\n",
      "military_list\n",
      "none_list\n",
      "vestment_list\n",
      "curtain_list\n",
      "college_list\n",
      "male_dress_list\n",
      "female_dress_list\n"
     ]
    }
   ],
   "source": [
    "a = [\"groom_list\",\"lab_list\",\"cinema_list\",\"piano_list\",\"barb_list\",\n",
    " \"military_list\",\"none_list\",\"vestment_list\",\"curtain_list\",\n",
    " \"college_list\",\"male_dress_list\",\"female_dress_list\"]\n",
    "\n",
    "#Note:\n",
    "\n",
    "# Affinity propagation can be viewed as a spectral clustering algorithm that requires each cluster to vote \n",
    "# for a good exemplar from within its data points. Hierarchical agglomerative clustering starts with every \n",
    "# data point as its own cluster and then recursively merges pairs of clusters, but that method makes hard \n",
    "# decisions that can cause it to get stuck in poor solutions. Affinity propagation can be viewed as a \n",
    "# version of hierarchical clustering that makes soft decisions so that it is free to hedge its bets when \n",
    "# forming clusters.\n",
    "\n",
    "#what you used: affinity propogation  An algorithm that identifies exemplars among data points and forms clusters of data points around these exemplars. ... It is similar to k-means clustering or the EM algorithm, except that the centers must lie on data points\n",
    "#affinity propogation is literally like a fancier k-means. But it doesn't give relative distances between the clusters which is annoying\n",
    "\n",
    "#total number of possibilities for each picture vs picture comparison (1024 choose 5 + 1024 choose 4 + 1024 choose 3 + 1024 choose 2 + 1024 choose 1 + 1024 choose 0)\n",
    "#because for 2 given pictures they can have 0-5 objects in common and those 0-5 objects are chosen from 1024 possible objects\n",
    " \n",
    "#Due to this infinite number of possibilities.... hierarchical clustering no longer made sense\n",
    "\n",
    "#maybe I need to do a data reduction on object clustering. Like if a photo is labelled as a chair should that be in a different category than a photo labelled as sitting?\n",
    "\n",
    "#affinity propogation clusters the photos by how similar or how many labels the photos have in common.\n",
    "#The results I get from this clustering doesn't necessarily imply that the photos have the same labels in common.\n",
    "#it means that if a photo is in a cluster, it shares more labels in common with this subset of photos than it does with any other cluster of photos.\n",
    "#This is useful if you say: \"I want a subset from the teenie harris archive that contains similar things.\"\n",
    "#This is also useful if you want to differentiate between photos with bow ties grooms and vestments vs piano bow ties grooms and vestments\n",
    "\n",
    "# if all the photos are equidistant from eachother in space then it's almost like the exemplars for the clusters are randomly chosen\n",
    "# and although the clusters are still useful for the fact that they can be represented by this exemplar and are similar to it. it's less useful\n",
    "\n",
    "#I have 2 options merge the subsets together with my own algorithm, or leave the clusters as they are.\n",
    "# Cannot re run the algorithm and lower the preferences to get less clusters because preferences is already set at its lowest value\n",
    "# preferences is set to the median similarity value in the similarity matrix which is 0 in this case because the similarity matrix is so sparse.\n",
    "\n",
    "#And you can do a search for subsets with particular labels assigned to them, and you can do that search through the results of hiearchical clustering\n",
    "\n",
    "#This means it's really important to get all of the labels that appear in the cluster and the frequency counts of each label\n",
    "#you already have the top 5 labels from each photo.\n",
    "\n",
    "# The reason why k-nearest neighbors wasn't chosen is because: A) we don't know k and k is subjective anyways.\n",
    "# B) K-nearest neighbors works well for smaller search spaces. i.e. 3 dimensions or less. since we have 1024 dimensions it'd be unlikely that we'd find correct centers so the clusters wouldn't mean anything\n",
    "#Hierarchical clustering, clusters the photos by what labels the photos have in common. 2^1024 possibilities for position in hiearchical clustering.\n",
    "\n",
    "\n",
    "### Task 1 for this script. For each cluster you'd like to find the photo that is the exemplar for the cluster, \n",
    "## what the labels in the cluster are and \n",
    "## a frequency chart of the labels containing the percentage of the photos in the cluster that each label shows up in.\n",
    "## This data should all be put into mongo as well. This means you need a new collection called Clusters in addition to Faces and Photos.\n",
    "## each cluster will contain the three things listed above previously.\n",
    "## In theory you could use the frequency table of labels to get distances between clusters and reduce them down some more\n",
    "## So some of these clusters are trash and only related to eachother by having one thing in common \n",
    "## and a set of things that they all exclude which pushes them together in euclidean space\n",
    "## assign a quality metric to clusters\n",
    "\n",
    "\n",
    "## Task 2 insert the top 5 image classification labels for each photo\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "\n",
    "client = MongoClient('localhost:27017')\n",
    "db = client.Teenie\n",
    "\n",
    "#labels_lab_list.pickle is zero bytes and affinityPropResults_groom_list.pickle is zero bytes\n",
    "centers,PhotoClusterDict = None, None\n",
    "top5 = None\n",
    "with open('top5perphotoDictionary.pickle', 'rb') as handle:\n",
    "    top5 = pickle.load(handle)\n",
    "quality_scores_ = [0]*40\n",
    "for tag in a: \n",
    "    \n",
    "    print tag  \n",
    "    all_photos_in_tag = np.load(tag+\".npy\")\n",
    "    with open('ClusterCenters/affinityPropResults_'+tag+'.pickle', 'rb') as handle2:\n",
    "        centers = pickle.load(handle2)\n",
    "\n",
    "    with open('Clusters/ClusterPhotoMapping_'+tag+'.pickle', 'rb') as handle3:\n",
    "        PhotoClusterDict = pickle.load(handle3)\n",
    "\n",
    "    for i in xrange(len(PhotoClusterDict.keys())):\n",
    "        new_data_point = {}\n",
    "        new_data_point[\"name\"] = tag+str(i)\n",
    "        new_data_point[\"tag\"] = tag\n",
    "        try:\n",
    "            new_data_point[\"exemplar\"] = db.Photos.find_one({\"path\" : {\"$regex\" : \".*/\" + all_photos_in_tag[centers[i]][:-5] + \".png\"}})[\"_id\"]\n",
    "        except:\n",
    "            print \"error1\", tag, all_photos_in_tag[centers[i]][:-5]\n",
    "        new_data_point[\"photos\"] = []\n",
    "        photos = PhotoClusterDict[i+1]\n",
    "        size = len(photos)\n",
    "        new_data_point[\"size\"] = size\n",
    "        if size < 1 : continue\n",
    "        for i in photos:\n",
    "            try:\n",
    "                new_id = db.Photos.find_one({\"path\" : {\"$regex\" : \".*/\" + i[:-5] + \".png\"}})[\"_id\"]\n",
    "                new_data_point[\"photos\"].append(new_id)\n",
    "            except:\n",
    "                print \"error2\", tag+str(i), i[:-5]\n",
    "        cluster_freq = {}\n",
    "        quality_score = 0 \n",
    "        # each label that is in more than 50% of the photos adds to the score\n",
    "        # every additional 7 photos adds to the score\n",
    "        # clusters with less than 7 photos get a quality score of zero\n",
    "        if len(new_data_point[\"photos\"]) == 0: continue\n",
    "        #Build Frequency Table for each cluster\n",
    "        for filename in photos:\n",
    "            p_labels = top5[filename]\n",
    "            try:\n",
    "                idd = db.Photos.find_one({\"path\" : {\"$regex\" : \".*/\" + filename[:-5] + \".png\"}})[\"_id\"]\n",
    "                db.Photos.update({'_id': idd},{'$set': {'Top5ObjClassifications': list(p_labels)}}, upsert=False, multi=False)\n",
    "            except:\n",
    "                print \"error3\", tag+str(i), filename[:-5] , filename, type(filename), len(filename), \"done\"\n",
    "            for label_ in p_labels: \n",
    "                if label_ in cluster_freq.keys():\n",
    "                    cluster_freq[label_] += 1\n",
    "                else:\n",
    "                    cluster_freq[label_] = 1 \n",
    "        \n",
    "        #Assign Quality Score for each cluster. This was purely subjective weighting. \n",
    "        # this metric gives me clusters that have a good amount of tags and a decent size according to my perception\n",
    "\n",
    "        for lab in cluster_freq:\n",
    "            if cluster_freq[lab]*1.0/size > 0.5 : quality_score +=3\n",
    "        quality_score += size/5\n",
    "        if size < 8 : quality_score = 0\n",
    "            \n",
    "        quality_scores_[quality_score] += 1\n",
    "        new_data_point[\"frequencies\"] = cluster_freq               \n",
    "        new_data_point[\"quality_score\"] = quality_score\n",
    "        db.Clusters.insert(new_data_point)\n",
    "#         if quality_score > 18: print cluster_name, center, photos, size, cluster_freq, quality_score\n",
    "\n",
    "#     print tag, quality_scores_ #shows the distribution for quality clusters for each tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'45762.jpeg'[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q= []\n",
    "q.append(5)\n",
    "q.append(6)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'n': 1, u'nModified': 1, u'ok': 1, 'updatedExisting': True}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.Photos.update({'_id': idd},{'$set': {'Top5ObjClassifications': list(p_labels)}}, upsert=False, multi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(p_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
